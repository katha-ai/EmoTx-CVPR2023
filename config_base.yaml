# Path variables
data_path: # After extracting the "EmoTx_min_feats.tar.gz" file, a "data" folder will be accessible, add the path to that folder here. (E.g. /home/user/data)
resource_path: # Use the same data_path string and add "/MovieGraph/resources/" at the end. (E.g. /home/user/data/MovieGraph/resources/)
clip_srts_path: # Use the same data_path string and add "/MovieGraph/srt/clip_srt/" at the end. (E.g. /home/user/data/MovieGraph/srt/clip_srt/)
emotic_mapping_path: # Use the same data_path string and add "/emotic_mapping.json" at the end. (E.g. /home/user/data/emotic_mapping.json)
pkl_path: # Use the same data_path string and add "/MovieGraph/mg/py3loader/" at the end. (E.g. /home/user/data/MovieGraph/mg/py3loader/)
save_path: # Add path to save checkpoints and metadata. (E.g. /home/user/checkpoints/)
saved_model_path: # Use the same data_path string and add "/pretrained_models" at the end. (E.g. /home/user/data/pretrained_models/)
hugging_face_cache_path: # Path to cache directory where you wish to store HuggingFace models, tokenizers, etc. (E.g. /home/user/.cache/)
dumps_path: "./dumps"

# Directory names
scene_feat_dir: "_scene_features"
face_feat_dir: "_face_features"
srt_feat_dir: "srt_feats"
tracks_dir: "character_tracks"
track_names_dir: "track_names"
track_name_metadata_dir: "track_names/metadata"
mg_videos_dir: "mg_videos"

# String variables
scene_feat_type: "mvit_v1" # "resnet50_places" # "generic"
face_feat_type: "resnet50_fer" # "emo" # "generic"
srt_feat_type: "independent" # "concat"
srt_feat_model: "roberta"
pkl_name: "2017-11-02-51-7637_py3.pkl"
char_detection:
  person_config: "cascade_rcnn_x101_64x4d_fpn.json"
  face_config: "mtcnn.json"
  person_det_model: "cascade_rcnn_x101_64x4d_fpn.pth"
  face_det_model: "mtcnn.pth"
  save_path: # Path+directory to save the person and face detections.

# Boolean variables
use_scene_feats: True
use_char_feats: True
use_srt_feats: True
get_scene_targets: True
get_char_targets: True
random_feat_selection: True
use_srt_cls_only: True
joint_character_modeling: True
srt_feat_pretrained: False
use_emotic_mapping: False
shuffle_characters: False

# Numerical variables
model_no: 4.0 # 1.1, 1.2, 2.1, 2.2, 3.0
vid_fps: 23.976023976023978
max_possible_vid_frame_no: 17500
character_name_selection_threshold: 0.5
target_prediction_threshold: 0.5
top_k: 10 # 25
feat_sampling_rate: 8
num_chars: 4
num_enc_layers: 2
max_feats: 300
max_srt_feats: 300
batch_size: 4
num_cpus: 9
epochs: 20
lr: 0.00001
gpu_id: 0
seed: 0

# WandB related variables
wandb:
  logging: False
  project: "" # WandB project name
  entity: "" # WandB username
  sweeps: False
  sweep_id: ""
  sweep_run_count: 100
model_name: ''
model_name_suffix: ''

# Static variables (Do not change)
action_feat_group_size: 32
feat_info:
  generic:
    scene_feat_dim: 2048
    face_feat_dim: 512
  emo:
    face_feat_dim: 4096
    weights: "vgg_m_face_bn_fer_dag.pth"
  resnet50_places:
    scene_feat_dim: 2048
    weights: "resnet50_places365.pth.tar"
  resnet50_fer:
    face_feat_dim: 2048
    weights: "resnet50_fer.pth"
  roberta:
    srt_feat_dim: 768
  mvit_v1:
    scene_feat_dim: 768
    weights: "MVIT_B_32x3_f294077834.pyth"
pos_weight:
  '10': [2.67218201, 2.91079295, 2.36587678, 4.29210134, 3.74098798, 4.70900322, 4.57456829, 4.96806723, 4.72741935, 5.60037175]
  '25': [3.76215098, 4.07158590, 3.36492891, 5.86289121, 5.14819760, 6.40353698, 6.22919937, 6.73949580, 6.42741935, 7.55947955, 8.63389121, 8.3597561, 8.26559356, 9.41855204, 8.39795918, 10.74744898, 11.75623269, 10.09638554, 10.93005181, 12.15714286, 12.62426036, 14.98958333, 12.70535714, 16.18283582, 17.56854839]
  '26': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  # '26': [6.95602606, 7.42241379, 4.56378132, 16.02090592, 41.11206897, 7.46620451, 19.96566524, 15.22923588, 1.61789925, 6.24777448, 38.71544715, 1.90428062, 18.15686275, 4.26400862, 52.09782609, 8.11380597, 1.03202995, 976.0, 1.29342723, 151.65625, 2.56829803, 167.44827586, 44.23148148, 3.28133216, 5.07587065, 6.59720062]
